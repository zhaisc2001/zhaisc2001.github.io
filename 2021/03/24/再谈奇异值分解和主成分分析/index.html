<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>再谈奇异值分解和主成分分析 | Sisicca</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  <meta name="keywords" content="unsupervised learning" />
  
  
  
  
  <meta name="description" content="奇异值分解属于是线性代数中的基本知识，而主成分分析可以使用奇异值分解来省略复杂的特征分解。奇异值分解其实是一种线性代数中的矩阵因子分解方法，它可以把任意一个实矩阵分解为三个矩阵相乘的形式，比如对于一个mn大小的矩阵来说，它可以把该矩阵分解为m\m的正交矩阵、非负对角元素降序排列的m*n矩形对角矩阵以及n*n的正交矩阵。《统计学习方法》中，认为奇异值分解可以看作是数据压缩的一种方法，压缩的损失是平方">
<meta property="og:type" content="article">
<meta property="og:title" content="再谈奇异值分解和主成分分析">
<meta property="og:url" content="http://xiangweixi.cn/2021/03/24/%E5%86%8D%E8%B0%88%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3%E5%92%8C%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/index.html">
<meta property="og:site_name" content="Sisicca">
<meta property="og:description" content="奇异值分解属于是线性代数中的基本知识，而主成分分析可以使用奇异值分解来省略复杂的特征分解。奇异值分解其实是一种线性代数中的矩阵因子分解方法，它可以把任意一个实矩阵分解为三个矩阵相乘的形式，比如对于一个mn大小的矩阵来说，它可以把该矩阵分解为m\m的正交矩阵、非负对角元素降序排列的m*n矩形对角矩阵以及n*n的正交矩阵。《统计学习方法》中，认为奇异值分解可以看作是数据压缩的一种方法，压缩的损失是平方">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://pic4.zhimg.com/v2-5ee98f8f3426b845bc1c5038ecd29593_b.jpg">
<meta property="article:published_time" content="2021-03-24T12:14:27.000Z">
<meta property="article:modified_time" content="2021-03-26T09:32:30.190Z">
<meta property="article:author" content="Uestc_Sicca">
<meta property="article:tag" content="unsupervised learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pic4.zhimg.com/v2-5ee98f8f3426b845bc1c5038ecd29593_b.jpg">
  
    <link rel="alternate" href="/atom.xml" title="Sisicca" type="application/atom+xml">
  

  

  <link rel="icon" href="/css/images/mylogo.jpg">
  <link rel="apple-touch-icon" href="/css/images/mylogo.jpg">
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Montserrat:700" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Roboto:400,300,300italic,400italic" rel="stylesheet" type="text/css">
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
  <style type="text/css">
    @font-face{font-family:futura-pt; src:url("/css/fonts/FuturaPTBold.otf") format("woff");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt-light; src:url("/css/fonts/FuturaPTBook.otf") format("woff");font-weight:lighter;font-style:normal;}
    @font-face{font-family:futura-pt-italic; src:url("/css/fonts/FuturaPTBookOblique.otf") format("woff");font-weight:400;font-style:italic;}
}

  </style>
  
<link rel="stylesheet" href="/css/style.css">


  
<script src="/js/jquery-3.1.1.min.js"></script>

  
<script src="/js/bootstrap.js"></script>


  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="/css/bootstrap.css" >

  
    
<link rel="stylesheet" href="/css/dialog.css">

  

  

  
    <link rel="stylesheet" href="/css/header-post.css" >
  

  
  
  

<meta name="generator" content="Hexo 5.3.0"></head>



  <body data-spy="scroll" data-target="#toc" data-offset="50">


  
  <div id="container">
    <div id="wrap">
      
        <header>

    <div id="allheader" class="navbar navbar-default navbar-static-top" role="navigation">
        <div class="navbar-inner">
          
          <div class="container"> 
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>

            
              <a class="brand" style="
                 margin-top: 0px;"  
                href="#" data-toggle="modal" data-target="#myModal" >
                  <img width="124px" height="124px" alt="Hike News" src="/css/images/mylogo.jpg">
              </a>
            
            
            <div class="navbar-collapse collapse">
              <ul class="hnav navbar-nav">
                
                  <li> <a class="main-nav-link" href="/">Home</a> </li>
                
                  <li> <a class="main-nav-link" href="/archives">Archives</a> </li>
                
                  <li> <a class="main-nav-link" href="/categories">Categories</a> </li>
                
                  <li> <a class="main-nav-link" href="/tags">Tags</a> </li>
                
                  <li> <a class="main-nav-link" href="/about">About</a> </li>
                
                  <li><div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>


</div></li>
            </div>
          </div>
                
      </div>
    </div>

</header>



      
            
      <div id="content" class="outer">
        
          <section id="main" style="float:none;"><article id="post-再谈奇异值分解和主成分分析" style="width: 75%; float:left;" class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" class="article-title" itemprop="name">
      再谈奇异值分解和主成分分析
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2021/03/24/%E5%86%8D%E8%B0%88%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3%E5%92%8C%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/" class="article-date">
	  <time datetime="2021-03-24T12:14:27.000Z" itemprop="datePublished">2021-03-24</time>
	</a>

      
    <a class="article-category-link" href="/categories/technology/">technology</a>

      
	<a class="article-views">
	<span id="busuanzi_container_page_pv">
		PV:<span id="busuanzi_value_page_pv"></span>
	</span>
	</a>

      

    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p>奇异值分解属于是线性代数中的基本知识，而主成分分析可以使用奇异值分解来省略复杂的特征分解。奇异值分解其实是一种线性代数中的矩阵因子分解方法，它可以把任意一个实矩阵分解为三个矩阵相乘的形式，比如对于一个m<em>n大小的矩阵来说，它可以把该矩阵分解为m\</em>m的正交矩阵、非负对角元素降序排列的m*n矩形对角矩阵以及n*n的正交矩阵。《统计学习方法》中，认为奇异值分解可以看作是数据压缩的一种方法，压缩的损失是平方损失。</p>
<h2 id="特征值与特征向量"><a href="#特征值与特征向量" class="headerlink" title="特征值与特征向量"></a>特征值与特征向量</h2><p> 对于n阶矩阵A，特征值与特征向量定义如下：<br>$$<br>Ax=\lambda x<br>$$<br>λ就是我们所说的特征值，x是一个n维的向量，他就是λ对应的特征向量；矩阵A的特征分解，需要我们求出所有的特征值以及它们对应的特征向量，此时将矩阵A进行特征分解，有：<br>$$<br>A=W\sum W^{-1}<br>$$<br>W是n个特征向量组成的n<em>n矩阵，∑是由n个特征值组成对角元素的对角n\</em>n矩阵。W中的所有特征向量都已经被我们做了标准化处理，是一个酋矩阵（幺正矩阵），即W<sub>T</sub>=W<sub>-1</sub>。</p>
<p>这里特征分解的是一个方阵，假如不是方针，我们就要使用奇异值分解了。</p>
<h2 id="奇异值分解"><a href="#奇异值分解" class="headerlink" title="奇异值分解"></a>奇异值分解</h2><p>由于之前一篇博文中将奇异值分解很多东西已经阐述过了，这里就不再啰嗦，放个图：</p>
<p><img src="https://pic4.zhimg.com/v2-5ee98f8f3426b845bc1c5038ecd29593_b.jpg" alt="img"></p>
<p>如何求得这三个矩阵呢？</p>
<p>网上有先确定右奇异值向量和左奇异值向量，然后再计算对角矩阵的方法，但我们以《统计学习方法》中的方法为准，它首先有<br>$$<br>||Ax||^2=x^TA^TAx=\lambda x^Tx=\lambda ||x||^2<br>$$<br>即对于矩阵A的奇异值𝛔有<br>$$<br>\sigma=\sqrt{\lambda}=\sqrt{\frac{||Ax||^2}{||x||^2}}<br>$$<br>∑的对角由𝛔降序排列，其他元素使用0进行填充；而V<sub>1</sub>作为正特征值对应的特征向量组成的n<em>r矩阵（r为矩阵的秩），V<sub>2</sub>作为零特征值对应的特征向量组成的n\</em>(n-r)矩阵，它们共同组成了矩阵V，即<br>$$<br>V=[V_1,V_2]<br>$$</p>
<p>$$<br>\sum=\begin{pmatrix} \sigma &amp; 0 \ 0 &amp; 0 \end{pmatrix}<br>$$</p>
<p>接下来确定U矩阵，我们可以使用对矩阵的乘积AA<sup>T</sup>进行特征分解的方法，这里我们使用李航老师书中的方法：<br>$$<br>u_j=\frac{1}{\sigma_j}Av_j,j=1,2,…,r<br>$$</p>
<p>$$<br>U_1=[u_1,u_2,…,u_r]<br>$$</p>
<p>这里我们先引入一个正交补的概念，即<br>$$<br>Y^\perp={x\in R^n|x^Ty=0,\forall y\in Y }<br>$$<br>此时Y是R<sup>n</sup>的子空间；此时前面的u<sub>1</sub>到u<sub>j</sub>组成了U<sub>1</sub>，我们令U<sub>2</sub>为A的值域R(A)的正交补，有<br>$$<br>U_2={u_{r+1},u_{r+2},…,u_m}<br>$$</p>
<p>$$<br>U=[U_1,U_2]<br>$$</p>
<p>numpy实现奇异值分解：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">A=np.array([[<span class="number">1</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">2</span>],[<span class="number">0</span>,<span class="number">0</span>]])</span><br><span class="line">U,s,V=np.linalg.svd(A)</span><br></pre></td></tr></table></figure>
<h2 id="主成分分析"><a href="#主成分分析" class="headerlink" title="主成分分析"></a>主成分分析</h2><p>我们先对奇异值分解做一个性质的了解，对于奇异值分解后得到的降序对角奇异值矩阵，我们需要注意到的是奇异值的见效速度是相当快的，前10%甚至前1%的奇异值就已经占所有奇异值之和99%以上的比例，于是我们可以选用前k个奇异值以及它们对应的左右奇异值向量来近似表达矩阵，这就是《统计学习方法》书中所说的截断奇异值分解，即<br>$$<br>A_{m*n}=U_{m*k}∑<em>{k*k}V^T</em>{k*n}<br>$$<br>在《百面机器学习》中，作者使用了从最大方差和最小平方误差两方面来解释主成分分析的原理、目标函数以及求解方法，其实它们分别对应的是《机器学习》中所提到的最大可分性和最近重构性。我们先从最近重构性入手，最近重构性要求的是样本点到这个超平面的距离都足够近，假设数据都进行了中心化，有m<em>n矩阵为[x<sup>(1)</sup>,x<sup>(2)</sup>,…,x<sup>(m)</sup>]<sup>T</sup>,x<sup>(i)</sup>是1\</em>n的向量，原坐标系经过投影变换之后得到的新坐标系为{w<sub>1</sub>,w<sub>2</sub>,…,w<sub>n</sub>}，w是标准正交基向量，即||w||<sub>2</sub>=1，同时w<sub>i</sub><sup>T</sup>w<sub>j</sub>=0(i≠j)，此时我们使用PCA要达到的目的是将数据从n维降到n’维，于是我们需要丢弃新坐标系中的某些标准正交基向量，使新的坐标系为{w<sub>1</sub>,w<sub>2</sub>,…,w<sub>n’</sub>}，假设x<sup>(i)</sup>投影到新坐标系中变为z<sup>(i)</sup>=(z<sup>(i)</sup><sub>1</sub>,z<sup>(i)</sup><sub>2</sub>,…,z<sup>(i)</sup><sub>n’</sub>),即x<sup>(i)</sup>在新坐标系中第j维的坐标为z<sup>(i)</sup><sub>j</sub>=w<sub>j</sub><sup>T</sup>x<sup>(i)</sup>，此时我们需要度量降维导致的信息损失，于是我们从z<sup>(i)</sup>还原到原来坐标系有<br>$$<br>\hat{x}^{(i)}=\sum_{j=1}^{n’}z^{(i)}_{j}\omega_j<br>$$<br>于是可以得到平方损失为<br>$$<br>\sum_{i=1}^m||\hat{x}^{(i)}-x^{(i)}||_2^2=-tr(W^TXX^TW)+const<br>$$<br>优化目标为<br>$$<br>\mathop{argmin}\limits_{W}\ -tr(W^TXX^TW)<br>$$</p>
<p>$$<br>s.t.W^TW=I<br>$$</p>
<p>这是由最近重构性得到的优化目标，而从最大可分性(最大方差)可以得到优化目标<br>$$<br>\mathop{argmax}\limits_{W}\ tr(W^TXX^TW)<br>$$</p>
<p>$$<br>s.t.W^TW=I<br>$$</p>
<p>PCA的正常流程如下：</p>
<p>输入：数据集X，降维维数n’</p>
<p>输出：新坐标系W</p>
<p>1.对数据进行规范化处理<br>$$<br>x^{(i)}\leftarrow x^{(i)}-\frac{1}{m}\sum_{i=1}^mx^{(i)}<br>$$<br>2.求矩阵的协方差矩阵X<sup>T</sup>X</p>
<p>3.对矩阵的协方差矩阵做特征分解，选取最大的n’个特征值对应的特征向量</p>
<p>4.将这些特征向量组成新坐标系W输出</p>
<p>当step3中特征分解比较复杂时，我们选择对X进行奇异值分解，选择前n’个特征值，以及对应的n’个右奇异值向量，得到n*n’矩阵V，新的坐标为满足Y=XV。</p>
<p>scikit-learn中的主成分分析就是使用的奇异值分解的方法，由于n’作为降维维数需要提前给出，我们可以选择重构阈值法得出n’的值。</p>
<p>调包实现PCA：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line">A=np.array([[<span class="number">1</span>,<span class="number">1</span>,<span class="number">7</span>],[<span class="number">2</span>,<span class="number">2</span>,-<span class="number">5</span>],[<span class="number">0</span>,<span class="number">0</span>,<span class="number">11</span>]])</span><br><span class="line">pca = PCA(n_components=<span class="number">0.95</span>)</span><br><span class="line">pca.fit(A)</span><br><span class="line">new_A = pca.fit_transform(A)</span><br><span class="line">print(pca.explained_variance_ratio_)</span><br></pre></td></tr></table></figure>
<p>最后一行代码可以查看选取的特征值之和占所有特征值之和的百分比。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1]周志华. 机器学习[M]. 清华大学出版社, 2016.</p>
<p>[2]刘建平Pinard.主成分分析（PCA）原理总结[EB/OL].<a target="_blank" rel="noopener" href="https://www.cnblogs.com/pinard/p/6239403.html,2016-12-31">https://www.cnblogs.com/pinard/p/6239403.html,2016-12-31</a>.</p>

      
    </div>
    <footer class="article-footer">
      
      
      <div>
        <ul class="post-copyright">
          <li class="post-copyright-author">
          <strong>Post author:  </strong>Uestc_Sicca</a>
          </li>
          <li class="post-copyright-link">
          <strong>Post link:  </strong>
          <a href="/2021/03/24/再谈奇异值分解和主成分分析/" target="_blank" title="再谈奇异值分解和主成分分析">http://xiangweixi.cn/2021/03/24/再谈奇异值分解和主成分分析/</a>
          </li>
          <li class="post-copyright-license">
            <strong>Copyright Notice:   </strong>
            All articles in this blog are licensed under <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">CC BY-NC-ND 4.0</a>
            unless stating additionally.
          </li>
         
        </ul>
<div>

      
      
        
	<div id="comment">
		<!-- 来必力City版安装代码 -->
		<div id="lv-container" data-id="city" data-uid="MTAyMC8yOTQ4MS82MDQ5">
		<script type="text/javascript">
		   (function(d, s) {
		       var j, e = d.getElementsByTagName(s)[0];

		       if (typeof LivereTower === 'function') { return; }

		       j = d.createElement(s);
		       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
		       j.async = true;

		       e.parentNode.insertBefore(j, e);
		   })(document, 'script');
		</script>
		<noscript>为正常使用来必力评论功能请激活JavaScript</noscript>
		</div>
		<!-- City版安装代码已完成 -->
	</div>



      
      
        
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/unsupervised-learning/" rel="tag">unsupervised learning</a></li></ul>

      

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2021/03/27/%E6%AD%BB%E4%BA%A1%E3%80%81%E8%87%AA%E7%94%B1%E3%80%81%E5%AD%A4%E7%8B%AC%E4%B8%8E%E6%97%A0%E6%84%8F%E4%B9%89/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          死亡、自由、孤独与无意义
        
      </div>
    </a>
  
  
    <a href="/2021/03/22/%E5%86%8D%E8%B0%88%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">再谈高斯混合模型</div>
    </a>
  
</nav>

  
</article>

<!-- Table of Contents -->

  <aside id="toc-sidebar">
    <div id="toc" class="toc-article">
    <strong class="toc-title">Contents</strong>
    
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E5%80%BC%E4%B8%8E%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F"><span class="nav-number">1.</span> <span class="nav-text">特征值与特征向量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3"><span class="nav-number">2.</span> <span class="nav-text">奇异值分解</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90"><span class="nav-number">3.</span> <span class="nav-text">主成分分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="nav-number">4.</span> <span class="nav-text">参考文献</span></a></li></ol>
    
    </div>
  </aside>

</section>
        
      </div>
      
      <footer id="footer">
  

  <div class="container">
      	<div class="row">
	      <p> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/iTimeTraveler/hexo-theme-hiker" target="_blank">Hexo-theme-hiker</a> </p>
	      <p id="copyRightEn">Copyright &copy; 2020 - 2021 Sisicca All Rights Reserved.</p>
	      
	      
    		<p class="busuanzi_uv">
				UV : <span id="busuanzi_value_site_uv"></span> |  
				PV : <span id="busuanzi_value_site_pv"></span>
		    </p>
  		   
		</div>

		
  </div>
</footer>


<!-- min height -->

<script>
    var wrapdiv = document.getElementById("wrap");
    var contentdiv = document.getElementById("content");
    var allheader = document.getElementById("allheader");

    wrapdiv.style.minHeight = document.body.offsetHeight + "px";
    if (allheader != null) {
      contentdiv.style.minHeight = document.body.offsetHeight - allheader.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    } else {
      contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    }
</script>
    </div>
    <!-- <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav> -->
    

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/scripts.js"></script>





  
<script src="/js/dialog.js"></script>









	<div style="display: none;">
    <script src="https://s95.cnzz.com/z_stat.php?id=1260716016&web_id=1260716016" language="JavaScript"></script>
  </div>



	<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
	</script>






  </div>

  <div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true" style="display: none;">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h2 class="modal-title" id="myModalLabel">设置</h2>
      </div>
      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">


      <div class="modal-body">
          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseOne" onclick="javascript:setFontSize();" aria-expanded="true" aria-controls="collapseOne">
              正文字号大小
            </a>
          </div>
          <div id="collapseOne" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingOne">
          <div class="panel-body">
            您已调整页面字体大小
          </div>
        </div>
      


          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseTwo" onclick="javascript:setBackground();" aria-expanded="true" aria-controls="collapseTwo">
              夜间护眼模式
            </a>
        </div>
          <div id="collapseTwo" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingTwo">
          <div class="panel-body">
            夜间模式已经开启，再次单击按钮即可关闭 
          </div>
        </div>

        <div>
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseThree" aria-expanded="true" aria-controls="collapseThree">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关 于&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
        </div>
         <div id="collapseThree" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingThree">
          <div class="panel-body">
            Sisicca
          </div>
          <div class="panel-body">
            Copyright © 2021 Uestc_Sicca All Rights Reserved.
          </div>
        </div>
      </div>


      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <div class="modal-footer">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
      </div>
    </div>
  </div>
</div>
  
  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
  
    <a id="menu-switch"><i class="fa fa-bars fa-lg"></i></a>
  
</body>
</html>