<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>百面机器学习-优化算法 | Sisicca</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  <meta name="keywords" content="machine learning" />
  
  
  
  
  <meta name="description" content="优化是应用数学的一个分支，也是机器学习的核心组成部分。实际上，机器学习算法&#x3D;模型表征+模型评估+优化算法。优化算法做的是在模型表征空间中国呢找到模型评估指标最好的模型，不同的优化算法对应的模型表征和评估指标不同，我们需要了解优化算法原理。 有监督学习的损失函数机器学习中关键一环是模型评估，损失函数定义了模型的评估指标，没有损失函数我们就无法比较模型，我们要针对具体的问题选取合适的损失函数。   有">
<meta property="og:type" content="article">
<meta property="og:title" content="百面机器学习-优化算法">
<meta property="og:url" content="http://xiangweixi.cn/2021/05/03/%E7%99%BE%E9%9D%A2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/index.html">
<meta property="og:site_name" content="Sisicca">
<meta property="og:description" content="优化是应用数学的一个分支，也是机器学习的核心组成部分。实际上，机器学习算法&#x3D;模型表征+模型评估+优化算法。优化算法做的是在模型表征空间中国呢找到模型评估指标最好的模型，不同的优化算法对应的模型表征和评估指标不同，我们需要了解优化算法原理。 有监督学习的损失函数机器学习中关键一环是模型评估，损失函数定义了模型的评估指标，没有损失函数我们就无法比较模型，我们要针对具体的问题选取合适的损失函数。   有">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2021-05-03T02:56:31.000Z">
<meta property="article:modified_time" content="2021-05-06T03:31:19.614Z">
<meta property="article:author" content="Uestc_Sicca">
<meta property="article:tag" content="machine learning">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Sisicca" type="application/atom+xml">
  

  

  <link rel="icon" href="/css/images/mylogo.jpg">
  <link rel="apple-touch-icon" href="/css/images/mylogo.jpg">
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Montserrat:700" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Roboto:400,300,300italic,400italic" rel="stylesheet" type="text/css">
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
  <style type="text/css">
    @font-face{font-family:futura-pt; src:url("/css/fonts/FuturaPTBold.otf") format("woff");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt-light; src:url("/css/fonts/FuturaPTBook.otf") format("woff");font-weight:lighter;font-style:normal;}
    @font-face{font-family:futura-pt-italic; src:url("/css/fonts/FuturaPTBookOblique.otf") format("woff");font-weight:400;font-style:italic;}
}

  </style>
  
<link rel="stylesheet" href="/css/style.css">


  
<script src="/js/jquery-3.1.1.min.js"></script>

  
<script src="/js/bootstrap.js"></script>


  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="/css/bootstrap.css" >

  
    
<link rel="stylesheet" href="/css/dialog.css">

  

  

  
    <link rel="stylesheet" href="/css/header-post.css" >
  

  
  
  

<meta name="generator" content="Hexo 5.3.0"></head>



  <body data-spy="scroll" data-target="#toc" data-offset="50">


  
  <div id="container">
    <div id="wrap">
      
        <header>

    <div id="allheader" class="navbar navbar-default navbar-static-top" role="navigation">
        <div class="navbar-inner">
          
          <div class="container"> 
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>

            
              <a class="brand" style="
                 margin-top: 0px;"  
                href="#" data-toggle="modal" data-target="#myModal" >
                  <img width="124px" height="124px" alt="Hike News" src="/css/images/mylogo.jpg">
              </a>
            
            
            <div class="navbar-collapse collapse">
              <ul class="hnav navbar-nav">
                
                  <li> <a class="main-nav-link" href="/">Home</a> </li>
                
                  <li> <a class="main-nav-link" href="/archives">Archives</a> </li>
                
                  <li> <a class="main-nav-link" href="/categories">Categories</a> </li>
                
                  <li> <a class="main-nav-link" href="/tags">Tags</a> </li>
                
                  <li> <a class="main-nav-link" href="/about">About</a> </li>
                
                  <li><div id="search-form-wrap">

    <form class="search-form" method="GET" action="https://www.baidu.com/s?">
    <input name="wd" type="text" class="search-form-input" placeholder="index.search" />
    <button type="submit" class="search-form-submit"></button>
</form>
<script>
(function ($) {
    $('.search-form').on('submit', function (e) {
        var keyword = $('.search-form-input[name="wd"]').val();
        window.location = 'https://www.baidu.com/s?wd=site:xiangweixi.cn ' + keyword;
        return false;
    });
})(jQuery);
</script>

</div></li>
            </div>
          </div>
                
      </div>
    </div>

</header>



      
            
      <div id="content" class="outer">
        
          <section id="main" style="float:none;"><article id="post-百面机器学习-优化算法" style="width: 75%; float:left;" class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" class="article-title" itemprop="name">
      百面机器学习-优化算法
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2021/05/03/%E7%99%BE%E9%9D%A2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/" class="article-date">
	  <time datetime="2021-05-03T02:56:31.000Z" itemprop="datePublished">2021-05-03</time>
	</a>

      
    <a class="article-category-link" href="/categories/technology/">technology</a>

      
	<a class="article-views">
	<span id="busuanzi_container_page_pv">
		PV:<span id="busuanzi_value_page_pv"></span>
	</span>
	</a>

      

    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p>优化是应用数学的一个分支，也是机器学习的核心组成部分。实际上，机器学习算法=模型表征+模型评估+优化算法。优化算法做的是在模型表征空间中国呢找到模型评估指标最好的模型，不同的优化算法对应的模型表征和评估指标不同，我们需要了解优化算法原理。</p>
<h2 id="有监督学习的损失函数"><a href="#有监督学习的损失函数" class="headerlink" title="有监督学习的损失函数"></a>有监督学习的损失函数</h2><p>机器学习中关键一环是模型评估，损失函数定义了模型的评估指标，没有损失函数我们就无法比较模型，我们要针对具体的问题选取合适的损失函数。</p>
<blockquote>
<ul>
<li><p>有监督学习涉及到的损失函数有哪些？请列举并简述它们的特点？(简单)</p>
<p>有监督学习中，损失函数刻画了模型和训练样本的匹配程度。假设训练样本的形式为(x<sub>i</sub>，y<sub>i</sub>)，其中x<sub>i</sub>表示第i个样本的特征，y<sub>i</sub>表示该样本的标签，参数为𝛉的模型可以表示为函数f(.,𝛉):X-&gt;Y，我们定义损失函数为L(.,.):YxY-&gt;R<sub>≥0</sub>，L(f(x<sub>i</sub>,𝛉))越小，表明模型在该样本点匹配得越好。</p>
<p>对二分类问题，Y={1,-1}，我们希望sign f(x<sub>i</sub>,𝛉)=y<sub>i</sub>，最自然的损失函数是0-1损失，即<br>$$<br>L_{0-1}(f,y)=1_{fy≤0}<br>$$<br>其中1<sub>p</sub>是指示函数(Indicator Function)，当且仅当P为真时取值为1，否则取值为0。该损失函数可以直观地刻画分类的错误率，但是由于它非凸、非光滑，对于这个函数的优化比较困难，它的一个代理函数是Hinge损失函数<br>$$<br>L_{hinge}(f,y)=max{0,1-fy}<br>$$<br>Hinge损失函数是0-1损失函数的一个凸上界，它在fy=1处不可导，因此它的优化方法不是SGD，而是次梯度下降法。0-1损失函数的另一个代理函数是Logistic损失函数<br>$$<br>L_{logistic}(f,y)=log_2(1+exp(-fY))<br>$$<br>它也是0-1损失函数的凸上界，而且它处处光滑，因此可以用梯度下降法优化，它对于所有的样本点都有所惩罚，因此logistic损失函数对异常点是敏感的。当预测值在-1到1之间时，我们使用交叉熵损失函数<br>$$<br>L_{crossentropy}(f,y)=-log_2(\frac{1+fy}{2})<br>$$<br>交叉熵损失函数也是0-1损失函数的光滑凸上界。</p>
<p>对于回归问题，我们最常用的损失函数时平方损失函数，它是光滑的，能够使用SGD进行优化，当预测值离实际值偏差较大，平方损失函数惩罚力度加大，因此它也是对于异常点敏感的，我们可以使用绝对损失函数来解决该问题<br>$$<br>L_{absolute}(f,y)=|f-y|<br>$$<br>绝对损失函数问题在于它在f=y处不是光滑的，我们可以使用Huber损失函数，这样既满足了可导性，也满足了对异常点的鲁棒性，Huber损失函数<br>$$<br>L_{Huber}(f,y)=(f-y)^2,when\ |f-y|≤\delta<br>$$</p>
<p>$$<br>L_{Huber}(f,y)=2\delta|f-y|-\delta^2,when\ |f-y|&gt;\delta<br>$$</p>
<p>它在|f-y|较小时为平方损失，在|f-y|较大时为线性损失，处处可导，且对异常点鲁棒。</p>
</li>
</ul>
</blockquote>
<h2 id="机器学习中的优化问题"><a href="#机器学习中的优化问题" class="headerlink" title="机器学习中的优化问题"></a>机器学习中的优化问题</h2><p>大部分机器学习的参数估计问题也可以写成优化问题，机器学习模型不同，损失函数不同，对应的优化问题也不相同。</p>
<blockquote>
<ul>
<li><p>机器学习中的优化问题，哪些时凸优化函数，哪些是非凸优化问题？各举一个例子。(较简单</p>
<p>我们首先对凸函数下一个严格定义，函数是凸函数当且仅当对于定义域中的任意两袋内x,y，和任意实数λ∈[0,1]总有<br>$$<br>L(\lambda x+(1-\lambda x)y)≤\lambda L(x)+(1-\lambda)L(y)<br>$$<br>该不等式的一个直观解释，凸函数曲面上任意两点连接而成的线段，其上的任意一点都不会处于该函数曲面的下方。（关于凹凸函数，有一个相当变态的事实就是在中文语境下的凹凸函数的定义和由外语翻译而来的凹凸函数的定义是相反的，国内的定义参照同济大学数学系的《高等数学.第七版》（上册）一个函数图像形似“凹”或“凸”则是凹函数或凸函数，而国外的定义参照Cambridge University的Convex Optimization则是函数上方是凸集的是凸函数，函数上方是凹集的是凹函数）</p>
<p>我们将逻辑回归作为一个例子，逻辑回归用于解决二分类问题，假设模型参数为𝛉，则逻辑回归的优化问题为<br>$$<br>\mathop{min}\limits_{\theta}L(\theta)\sum_{i=1}^{n}log(1+exp(-y_i\theta^Tx_i))<br>$$<br>可以通过计算目标函数的二阶Hessian矩阵来验证凸性。</p>
<p>求一阶导，得到<br>$$<br>\triangledown L_i(\theta)=\frac{1}{1+exp(-y_i\theta^Tx_i)}exp(-y_i\theta^Tx_i)(-y_ix_i)=\frac{-y_ix_i}{1+exp(y_i\theta^Tx_i)}<br>$$<br>继续求导，得到Hessian矩阵<br>$$<br>\triangledown^2L_i(\theta)=\frac{y_ix_iexp(y_i\theta^Tx_i)y_ix^T_i}{(1+exp(y_i\theta^Tx_i))}=\frac{exp(y_i\theta^Tx_i)}{(1+exp(y_i\theta^Tx_i))^2}x_ix_i^T<br>$$<br>该矩阵满足半正定的性质，因此函数为凸函数，对于凸优化问题来说，所有的局部极小值都是全局极小值，因此凸优化问题是容易求解的问题。</p>
<p>主成分分析对应的优化问题是非凸优化问题，若数据中心化后的矩阵，主成分分析优化问题<br>$$<br>\mathop{min}\limits_{VV^T=I_k}L(V)=||X-V^TVX||^2_F<br>$$<br>是一个非凸优化问题，一般来说，非凸优化问题是比较难求解的问题。主成分分析是一个特例，因为我们可以使用SVD来直接求得主成分分析的全局极小值。</p>
<p>其他的凸优化问题有支持向量机、线性回归等线性模型，非凸优化问题有矩阵分解(低秩模型)、深度神经网络模型等。</p>
</li>
</ul>
</blockquote>
<h2 id="经典优化算法"><a href="#经典优化算法" class="headerlink" title="经典优化算法"></a>经典优化算法</h2><p>针对不同的优化问题和应用场景，研究者们提出了多种不同的解法，并逐渐发展出了有严格理论支撑的凸优化领域，我们来看一些有助于我们面对新的优化问题得到思路的经典优化算法。</p>
<blockquote>
<ul>
<li><p>无约束优化问题的优化方法有哪些？(较简单)</p>
<p>假设有一道无约束优化问题：<br>$$<br>\mathop{min}\limits_{\theta}L(\theta)<br>$$<br>其中目标函数是光滑的，请问求解该问题的优化算法有哪些？适用场景为？</p>
<p>经典的优化算法可以分为直接法和迭代法两大类。</p>
<p>直接法，顾名思义就是能够直接给出优化问题最优解的方法。虽然听起来很厉害，但在很多时候它都是无法使用的。第一个条件，L是凸函数，此时最优解的条件就是<br>$$<br>\triangledown L(\theta^*)=0<br>$$<br>为了能够求出这个最优解，第二个条件就是，上式有闭式解(解析解)。我们举一个经典的满足这两个条件的例子，岭回归(Ridge Regerssion)，目标函数为<br>$$<br>L(\theta)=||X\theta-y||^2_2+\lambda||\theta||^2_2<br>$$<br>求解得到最优解为<br>$$<br>\theta^*=(X^TX+\lambda I)^{-1}X^Ty<br>$$<br>直接法要满足的这两个条件限制了它的应用范围。因此在很多实际问题中，会采用迭代法，迭代法通过迭代地修正对最优解的估计，假设当前对最优解的估计值为𝛉<sub>t</sub>，希望求解优化问题<br>$$<br>\delta_t=\mathop{argmin}\limits_{\delta}L(\theta_t+\delta)<br>$$<br>得到更好的估计值𝛉<sub>t+1</sub>。迭代法可以分为一阶法和二阶法两类。</p>
<p>一阶法对函数L做一阶泰勒展开，得到近似式<br>$$<br>L(\theta_t+\delta)\approx L(\theta_t)+\triangledown L(\theta_t)^T\delta<br>$$<br>该近似式只有在𝛅较小时才比较准确，因此求解𝛅<sub>t</sub>一般加上L<sub>2</sub>正则项<br>$$<br>\delta_t=\mathop{argmin}\limits_{\delta}(L(\theta_t)+\triangledown L(\theta_t)^T\delta +\frac{1}{2\alpha}||\delta||^2_2)=-\alpha\triangledown L(\theta_t)<br>$$<br>一阶法的迭代公式表示为<br>$$<br>\theta_{t+1}=\theta_{t}-\alpha\triangledown L(\theta_t)<br>$$<br>二阶法对函数L(𝛉<sub>t</sub>+𝛅)做二阶泰勒展开，得到近似式<br>$$<br>L(\theta_t +\delta)\approx L(\theta_t)+\triangledown L(\theta_t)^T\delta+\frac{1}{2}\delta^T\triangledown^2L(\theta_t)\delta<br>$$<br>其中对L求两次导数是L的Hessian矩阵，通过求解近似优化问题<br>$$<br>\delta_t=\mathop{argmin}\limits_{\delta}(L(\theta_t)+\triangledown L(\theta_t)^T\delta+\frac{1}{2}\delta\triangledown^2L(\theta_t)\delta)=-\triangledown^2L(\theta_t)^{-1}\triangledown L(\theta_t)<br>$$<br>可以得到二阶法的迭代公式<br>$$<br>\theta_{t+1}=\theta_t-\triangledown^2L(\theta_t)^{-1}\triangledown L(\theta_t)<br>$$<br>二阶法也称为牛顿法，Hessian矩阵就是目标函数的二阶信息。二阶法的收敛速度一般快于一阶法，高维情况，Hessian矩阵求逆的计算复杂度很大，而且在目标函数非凸时，二阶法可能会收敛到鞍点(Saddle point)。</p>
</li>
</ul>
</blockquote>
<h2 id="梯度验证"><a href="#梯度验证" class="headerlink" title="梯度验证"></a>梯度验证</h2><p>使用梯度下降法，最重要的操作是计算目标函数的梯度，对于较复杂的模型，比如深度神经网络来说，目标函数的梯度公式也会相应地变复杂，因此实际应用中，写出计算梯度的代码后，通常要验证。</p>
<blockquote>
<ul>
<li><p>如何验证求目标函数梯度功能的正确性？(较容易)</p>
<p>根据梯度的定义，我们有<br>$$<br>\nabla L(\theta)=[\frac{\partial L(\theta)}{\partial \theta_1},…,\frac{\partial L(\theta)}{\partial \theta_n}]<br>$$<br>其中对于任意的i=1,2,…,n。梯度的第i个元素的定义为<br>$$<br>\frac{\partial L(\theta)}{\partial \theta_i}=\mathop{lim}\limits_{h\rightarrow0}\frac{L(\theta+he_i)-L(\theta-he_i)}{2h}<br>$$<br>其中e<sub>i</sub>是单位向量，维度和𝛉相同，但只在第i个位置取1，其余位置取0.因此我们将h取一个极接近于0的值，那么偏导数就约等于右式。我们使用泰勒展开来近似该误差，令但变量函数<br>$$<br>\tilde{L}(x)=L(\theta+xe_i)<br>$$<br>根据泰勒展开及拉格朗日余项公式，有<br>$$<br>L(\theta+he_i)=\tilde{L}(h)=\tilde{L}(0)+\tilde{L}’(0)h+\frac{1}{2}\tilde{L}’’(0)h^2-\frac{1}{6}\tilde{L}^{(3)}(p_i)h^3<br>$$<br>其中p<sub>i</sub>∈(0,h)，同理我们也能得到he<sub>i</sub>项前为-时的Lagrange余项泰勒展开，两式相减，等号两边同时除以2h，并且由于<br>$$<br>\tilde{L}’(0)=\frac{\partial L(\theta)}{\partial \theta_i}<br>$$<br>可得<br>$$<br>\frac{L(\theta+he_i)-L(\theta-he_i)}{2h}=\frac{\partial L(\theta)}{\partial\theta_i}+\frac{1}{12}(\tilde{L}^{(3)}(p_i)+\tilde{L}^{(3)}(q_i))h^2<br>$$<br>h充分小时，我们可以近似认为h<sup>2</sup>项前面的系数是常数M，因此近似式的误差为<br>$$<br>|\frac{L(\theta+he_i)-L(\theta-he_i)}{2h}-\frac{\partial L(\theta)}{\partial \theta_i}|\approx Mh^2<br>$$<br>这个近似误差显然是h的高阶无穷小。</p>
<p>实际应用中，我们随机初始化𝛉，取h为较小的数，并对i依次检验<br>$$<br>|\frac{L(\theta+he_i)-L(\theta-he_i)}{2h}-\frac{\partial L(\theta)}{\partial \theta_i}|≤h<br>$$<br>是否成立。如果对于某个下标i不成立，可能的问题是(1)该下标对应的M过大；(2)该梯度分量计算不正确。此时固定𝛉，减小h，并再次计算下表对应的近似误差，若近似误差约减小为减小的h的程度的平方，那么说明是第一个问题，我们应该使用更小的h重新做一次梯度验证；否则对应于第二种可能，我们应该检查求梯度的代码是否有错误。</p>
</li>
</ul>
</blockquote>
<h2 id="随机梯度下降法"><a href="#随机梯度下降法" class="headerlink" title="随机梯度下降法"></a>随机梯度下降法</h2><p>经典的优化方法，在每次迭代时需要使用所有的训练数据，这给求解大规模数据的优化问题带来了挑战。</p>
<blockquote>
<ul>
<li><p>当训练数据量特别大时，经典的梯度下降法存在什么问题，需要做如何改进？(容易)</p>
<p>优化问题的目标函数通常可以表示成<br>$$<br>L(\theta)=E_{(x,y)\sim P_{data}}L(f(x,\theta),y)<br>$$<br>模型学习任务为<br>$$<br>\theta^*=argminL(\theta)<br>$$<br>经典的梯度下降法采用所有训练数据的平均损失来近似目标函数，即<br>$$<br>L(\theta)=\frac{1}{M}\sum_{i=1}^ML(f(x_i,\theta),y_i)<br>$$</p>
<p>$$<br>\nabla L(\theta)=\frac{1}{M}\sum_{i=1}^{M}\nabla L(f(x_i,\theta),y_i)<br>$$</p>
<p>M是训练样本的个数，模型参数的更新公式为<br>$$<br>\theta_{t+1}=\theta_t-\alpha \nabla L(\theta_t)<br>$$<br>因此，经典的梯度下降法在每次对模型参数进行更新时需要遍历所有的数据，为了解决该问题，提出了随机梯度下降法(Stochastic Gradient Descent, SGD)用单个训练样本的损失来近似平均损失，即<br>$$<br>L(\theta;x_i,y_i)=L(f(x_i,\theta),y_i)<br>$$</p>
<p>$$<br>\nabla L(\theta;x_i,y_i)=\nabla L(f(x_i,\theta),y_i)<br>$$</p>
<p>因此，随机梯度下降法用单个训练数据也可以对模型参数进行一次更新，大大加快了收敛速率，该方法也非常适用于在线更新场景。</p>
<p>为了降低随机梯度的方差，从而使得迭代算法更加稳定，也为了充分利用高度优化的矩阵运算操作</p>
</li>
</ul>
</blockquote>

      
    </div>
    <footer class="article-footer">
      
      
      <div>
        <ul class="post-copyright">
          <li class="post-copyright-author">
          <strong>Post author:  </strong>Uestc_Sicca</a>
          </li>
          <li class="post-copyright-link">
          <strong>Post link:  </strong>
          <a href="/2021/05/03/百面机器学习-优化算法/" target="_blank" title="百面机器学习-优化算法">http://xiangweixi.cn/2021/05/03/百面机器学习-优化算法/</a>
          </li>
          <li class="post-copyright-license">
            <strong>Copyright Notice:   </strong>
            All articles in this blog are licensed under <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">CC BY-NC-ND 4.0</a>
            unless stating additionally.
          </li>
         
        </ul>
<div>

      
      
        
	<div id="comment">
		<!-- 来必力City版安装代码 -->
		<div id="lv-container" data-id="city" data-uid="MTAyMC8yOTQ4MS82MDQ5">
		<script type="text/javascript">
		   (function(d, s) {
		       var j, e = d.getElementsByTagName(s)[0];

		       if (typeof LivereTower === 'function') { return; }

		       j = d.createElement(s);
		       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
		       j.async = true;

		       e.parentNode.insertBefore(j, e);
		   })(document, 'script');
		</script>
		<noscript>为正常使用来必力评论功能请激活JavaScript</noscript>
		</div>
		<!-- City版安装代码已完成 -->
	</div>



      
      
        
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/" rel="tag">machine learning</a></li></ul>

      

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2021/04/27/%E7%99%BE%E9%9D%A2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">百面机器学习-概率图模型</div>
    </a>
  
</nav>

  
</article>

<!-- Table of Contents -->

  <aside id="toc-sidebar">
    <div id="toc" class="toc-article">
    <strong class="toc-title">Contents</strong>
    
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">1.</span> <span class="nav-text">有监督学习的损失函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98"><span class="nav-number">2.</span> <span class="nav-text">机器学习中的优化问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BB%8F%E5%85%B8%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95"><span class="nav-number">3.</span> <span class="nav-text">经典优化算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E9%AA%8C%E8%AF%81"><span class="nav-number">4.</span> <span class="nav-text">梯度验证</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95"><span class="nav-number">5.</span> <span class="nav-text">随机梯度下降法</span></a></li></ol>
    
    </div>
  </aside>

</section>
        
      </div>
      
      <footer id="footer">
  

  <div class="container">
      	<div class="row">
	      <p> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/iTimeTraveler/hexo-theme-hiker" target="_blank">Hexo-theme-hiker</a> </p>
	      <p id="copyRightEn">Copyright &copy; 2020 - 2021 Sisicca All Rights Reserved.</p>
	      
	      
    		<p class="busuanzi_uv">
				UV : <span id="busuanzi_value_site_uv"></span> |  
				PV : <span id="busuanzi_value_site_pv"></span>
		    </p>
  		   
		</div>

		
  </div>
</footer>


<!-- min height -->

<script>
    var wrapdiv = document.getElementById("wrap");
    var contentdiv = document.getElementById("content");
    var allheader = document.getElementById("allheader");

    wrapdiv.style.minHeight = document.body.offsetHeight + "px";
    if (allheader != null) {
      contentdiv.style.minHeight = document.body.offsetHeight - allheader.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    } else {
      contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    }
</script>
    </div>
    <!-- <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav> -->
    

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/scripts.js"></script>





  
<script src="/js/dialog.js"></script>









	<div style="display: none;">
    <script src="https://s95.cnzz.com/z_stat.php?id=1260716016&web_id=1260716016" language="JavaScript"></script>
  </div>



	<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
	</script>






  </div>

  <div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true" style="display: none;">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h2 class="modal-title" id="myModalLabel">设置</h2>
      </div>
      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">


      <div class="modal-body">
          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseOne" onclick="javascript:setFontSize();" aria-expanded="true" aria-controls="collapseOne">
              正文字号大小
            </a>
          </div>
          <div id="collapseOne" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingOne">
          <div class="panel-body">
            您已调整页面字体大小
          </div>
        </div>
      


          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseTwo" onclick="javascript:setBackground();" aria-expanded="true" aria-controls="collapseTwo">
              夜间护眼模式
            </a>
        </div>
          <div id="collapseTwo" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingTwo">
          <div class="panel-body">
            夜间模式已经开启，再次单击按钮即可关闭 
          </div>
        </div>

        <div>
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseThree" aria-expanded="true" aria-controls="collapseThree">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关 于&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
        </div>
         <div id="collapseThree" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingThree">
          <div class="panel-body">
            Sisicca
          </div>
          <div class="panel-body">
            Copyright © 2021 Uestc_Sicca All Rights Reserved.
          </div>
        </div>
      </div>


      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <div class="modal-footer">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
      </div>
    </div>
  </div>
</div>
  
  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
  
    <a id="menu-switch"><i class="fa fa-bars fa-lg"></i></a>
  
</body>
</html>